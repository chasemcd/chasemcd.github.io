<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Chase  McDonald


</title>
<meta name="description" content="Chase McDonald is a PhD student at Carnegie Mellon University.">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>☆</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="chasemcd.github.io/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <!-- <a class="nav-link" href="/blog/">
              blog
              
            </a> -->
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-151348235-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-151348235-1');
  </script>

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Chase</span>  McDonald
    </h1>
     <p class="desc"><tt>     chasemcd [at] cmu [dot] edu </tt></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        
        

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/portrait_circle-480.webp">
    
      <source media="(max-width: 800px)" srcset="/assets/img/portrait_circle-800.webp">
    
      <source media="(max-width: 1400px)" srcset="/assets/img/portrait_circle-1400.webp">
    

    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/portrait_circle.png">

  </source></source></source></picture>

  

</figure>

      
      
    </div>
    

    <div class="clearfix">
      <p>I’m a student at Carnegie Mellon University pursuing a <a href="https://www.cmu.edu/dietrich/sds/graduate/index.html" target="_blank" rel="noopener noreferrer">Ph.D. in Cognitive Decision Science</a>. In December 2022, I received an <a href="https://www.ml.cmu.edu/" target="_blank" rel="noopener noreferrer">M.S. in Machine Learning</a> and before that a B.A. in Computational Social Science (through the <a href="https://www.honors.ucla.edu/other-programs/design-your-own-major/" target="_blank" rel="noopener noreferrer">individual major program</a>) from UCLA. I am interested in cooperative artificial intelligence and the design of human-compatible autonomous systems. In my work, I ask how we can design AI to complement human decision-making and improve human experiences.</p>

<p>In tandem with my graduate studies, I am a Research Scientist on Riot Games’ Game AI team, where I conduct applied research on multi-agent reinforcement learning.</p>

<!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Feb 25, 2025</th>
          <td>
            
              I will give a spotlight talk at the AAAI Bridge Program, Collaborative AI and Modelling of Humans Bridge Program, on our work developing controllable reinforcement learning agents and evaluating human preferences for control in collaborative domains.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 23, 2024</th>
          <td>
            
              Presented at two AAAI symposia (Oct. 2023 and Feb. 2024) for our work on human-like credit assignment and using LLMs to learn from instructions!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec 21, 2022</th>
          <td>
            
              Completed the Master’s in Machine Learning at Carnegie Mellon!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 21, 2022</th>
          <td>
            
              Received the Tata Consultancy Services Presidential Fellowship at Carnegie Mellon!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 12, 2022</th>
          <td>
            
              Joined <a href="https://www.riotgames.com/" target="_blank" rel="noopener noreferrer">Riot Games</a> as a <del>Data Scientist</del> Research Scientist to work on applied research in their Game AI team.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected papers</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">in revision</abbr>
    
  
  </div>

  <div id="MCDONALD_COGRID_IG" class="col-sm-8">
    
      <div class="title">CoGrid and Interactive Gym: A Framework for Multi-Agent Experimentation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>McDonald, C.</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gonzalez, C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In revision.</em>
      
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The increasing integration of artificial intelligence (AI) into daily life highlights the importance of studying human interaction with autonomous agents. While much of the existing research focuses on the training of highly skilled agents, there is a need to understand how these agents behave in multi-agent contexts, particularly in their interaction with humans. This paper introduces a framework with two tools to support research on human-AI interaction: COGRID and INTERACTIVE GYM. COGRID is a library that extends an existent Minigrid library for multi-agent simulations and generalizes it for easy customizability. INTERACTIVE GYM uses simulation environments that follow the existing Gymnasium or PettingZoo APIs and translates them directly into interactive experiments in a web browser. Both tools are open-sourced and available to the broader research community, with documentation and source code available at {cogrid, interactive-gym}.readthedocs.io. This paper details the functionality of these tools and presents several case studies to illustrate their utility in Human-AI multi-agent experimentation.
</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">preprint</abbr>
    
  
  </div>

  <div id="GANDHI_BTE" class="col-sm-8">
    
      <div class="title">Beliefs that Entertain</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Gandhi, A.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Giuliano, P.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Guan, E.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Keefer, Q.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>McDonald, C.</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Pagel, M.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tasoff, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>National Bureau of Economic Research</em>
      
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Economic research on entertainment is scant despite its large share of time use. We test economic theories of belief-based utility in the context of video-game engagement. Using data on 2.8 million matches from League of Legends, we find evidence supporting reference-dependent preferences, loss aversion, preferences for surprise and suspense, preferences for clumped surprise, and flow theory from psychology. We then leverage our estimated model and an evolutionary algorithm to find the information-revealing process that maximizes player engagement. We find that the optimal version of the game has increased game play equivalent to 43% of the winner-loser gap.
</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">in review</abbr>
    
  
  </div>

  <div id="MCDONALD_CI" class="col-sm-8">
    
      <div class="title">Exploring the Effects of Collective Intelligence Awareness in Real-Time Team Decision Making</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>McDonald, C.</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nguyen, T. N.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Botelho, C.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dishop, C.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Woolley, A.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gonzalez, C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Collective Intelligence</em>
      
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A growing body of research highlights the importance of collective intelligence in determining team success. Recent studies have explored the effectiveness of real-time collaborative process metrics to measure and predict collective intelligence as teams collaborate, offering potential avenues to improve team performance through targeted interventions. This research presents two experiments in which teams collaborated on an online search and rescue task, with some teams exposed to real-time displays of their collaborative process metrics. Contrary to expectations, our results do not uniformly support the notion that providing a real-time display of collaborative process metrics reliably improves team performance. Instead, we observed instances in which teams altered their behavior to optimize a particular metric, negatively impacting other processes and long-term performance. These results prompt a critical examination of the implications for designing digital nudges as real-time interventions aimed at improving collaborative processes and collective intelligence in teams.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">aaai</abbr>
    
  
  </div>

  <div id="NGUYEN23_CA" class="col-sm-8">
    
      <div class="title">Credit Assignment: Challenges and Insights to Develop Human-like AI Systems</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Nguyen, T. N.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>McDonald, C.</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gonzalez, C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceeding of the 2024 AAAI Spring Symposium on Human-Like Learning</em>
      
      
        Feb
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Temporal credit assignment is the process of linking delayed outcomes to specific actions in a sequence, crucial for learning and decision-making in dynamic settings. While computational methods in reinforcement learning, such as temporal difference (TD), address this issue, it remains unclear if these mechanisms align with how humans handle feedback delays. Cognitive science has yet to fully explore the credit assignment problem in humans and cognitive models. This study employs a cognitive model based on Instance-Based Learning Theory (IBLT) to examine mechanisms like equal credit, exponential credit, and TD credit in a goal-seeking navigation task with feedback delays and varying decision complexity. Comparing models with human behavior in two experiments, we find that no single mechanism fully explains human learning. Equal credit assignment aligns more closely with humans initially, while TD models start slower but surpass human accuracy over time. Decision complexity affects humans but not models. Notably, TD models exhibit initial over-exploration, while humans under-explore and tend to engage with distractors early on. These findings underscore the challenges and opportunities in developing learning agents that emulate human decision-making by incorporating human-like tendencies in handling delayed feedback under various decision complexities.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">aaai</abbr>
    
  
  </div>

  <div id="MCDONALD23_LLMINSTRUCTIONS" class="col-sm-8">
    
      <div class="title">Exploring the Path from Instructions to Rewards with Large Language Models in Instance-Based Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>McDonald, C.</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Malloy, T.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nguyen, T. N.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gonzalez, C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 2023 AAAI Fall Symposium on Integrating Cognitive Architectures and Generative Models</em>
      
      
        Oct
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A prominent method to model human learning is through experiential learning, where decisions are influenced by the outcomes observed in previous actions. The decisions-from- experience approach often excludes other forms of learning in humans, such as learning from descriptive information. In humans, descriptive information can enhance learning by pro- viding a denser signal, achieved through understanding the relationship between intermediate decisions and their future outcomes, instead of relying solely on observed outcomes. To account for experiential and descriptive information, we propose the use of large language models (LLMs) to convert descriptive information into dense signals that can be used by computational models that learn from experience. Building on past work in cognitive modeling, we utilize task instruc- tions and prompt an LLM to define and quantify the critical actions an agent must take to succeed in the task. In an initial experiment, we test this approach using an Instance-Based Learning cognitive model of experiential decisions in a grid- world task. We demonstrate how the LLM can be prompted to provide a series of actions and relative values given the task instructions, then show how these values can be used in place of sparse outcome signals to improve the model’s learning of the task significantly.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">iccm</abbr>
    
  
  </div>

  <div id="MCDONALD21_DIVERSITY" class="col-sm-8">
    
      <div class="title">Diverse Experience Leads to Improved Adaptation: An experiment with a cognitive model of learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>McDonald, C.</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bugbee, E.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  McCormick, E.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fiechter, J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Blaha, L,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lebiere, C.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gonzalez, C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Cognitive Modeling</em>
      
      
        Jul
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In dynamic decision tasks, the situations we confront are never the same: the world is constantly changing. Generally, our ability to generalize learned skills depends on the similarity between the learned skills and the situations in which we will apply those skills. However, in dynamic tasks, the situations we are trained in will most likely be different from the situations in which we need to apply skills. For example, in the face of emergencies, one could be trained to handle hypothetical disaster scenarios, but remain unprepared for the emergency that is actually experienced. This raises an important question: how can we best prepare for the unexpected? Cognitive science research suggests that heterogeneity during training helps people adapt to unexpected situations. However, evidence for a general diversity hypothesis is limited. In this research, we investigate this Diversity Hypothesis using a cognitive model of learning and decisions from experience based on Instance-Based Learning (IBL) Theory. We focus on the concept of decision complexity to investigate whether confronting decisions of diverse complexities results in improved adaptation to unexpected decision complexities, compared to situations of constant decision complexity. We conduct a simulation experiment using an IBL model in a Gridworld task, and expose agents to various degrees of diversity as they learn; we then observe how these agents transfer their acquired knowledge to a situation of novel decision complexity. Our results support the Diversity Hypothesis and the benefits of diversity on adaptation.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    
  </article>

</div>


<!-- Panelbear -->
<script async src="https://cdn.panelbear.com/analytics.js?site=AluaRYMBKFj"></script>
<script>
    window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    panelbear('config', { site: 'AluaRYMBKFj' });
</script>

    </div>

    <!-- Footer -->

    <!-- 
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Chase  McDonald.
    
    
    
    Last updated: February 05, 2025.
    
  </div>
</footer>
 -->


  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
